<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[「学生宿舍管理系统」实验报告]]></title>
    <url>%2F%E5%91%A8%E5%AE%87%E6%B4%8B_%E3%80%8C%E5%AD%A6%E7%94%9F%E5%AE%BF%E8%88%8D%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%E3%80%8D%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A%2F</url>
    <content type="text"><![CDATA[「学生宿舍管理系统」实验报告（第一次作业） 班级： 2017211317 学号： 2017211133 班内序： 11 姓名： 周宇洋 问题描述使用Python语言，设计一个小型的学生宿舍管理系统，系统用户为宿舍管理员。 功能要求 学生信息：学号、姓名、性别（男/女）、宿舍房间号、联系电话。 系统功能 可按学号查找某一位学生的具体信息 可以录入新的学生信息 可以显示现有的所有学生信息 程序要求 使用函数、列表、字典、字符串、条件循环等解决问题； 程序规模在80~200行左右。 任务分析实现宿舍管理程序的三个功能。添加的功能包括：可以利用学生的姓名进行查找。错误处理：在功能选择、输入学号、姓名、性别、宿舍房间号、联系电话时都有可能出现数据格式不正确的情况，需要请求用户重新输入。在查找失败时，需要向用户提供查找失败信息。 模块划分共有一个主函数和三个模块函数： search_stu可按照学号查找某一位学生的具体信息。（这里做了一个功能拓展，可以通过学生姓名来进行查找，如果有重名的同学都会查找出来） add_stu模块录入新的学生信息 show_all_students显示现有的所有学生信息 main函数进行功能选择 数据结构和关键算法 导入prettytable模块，使输出结果更为美观。 stu_info是一个$n * 5$ 的数组，其中$n$为学生数量 程序代码search_stu函数def search_stu(): "按照学号或姓名查找某一位学生的具体信息" find = -1 t = PrettyTable(["学号","姓名","性别","宿舍房间号","联系电话"]) sea = input("请输入要搜索的学号或姓名： ") if sea.isdigit() == True: for i in range(len(stu_info)): if stu_info[i][0] == sea: find = i t.add_row(stu_info[i]) if sea.isalpha() == True: count = 0 for i in range(len(stu_info)): if stu_info[i][1] == sea: find = i t.add_row(stu_info[i]) if find == -1: print("抱歉，未查找到该学生。") else: print(t) add_stu函数def add_stu(): "录入新的学生信息" print("-"*50) print("新增学生") num = input("请输入学号： ") while num.isdigit() != True: num = input("输入错误，请重新输入： ") name = input("请输入姓名： ") while name.isalpha() != True: name = input("输入错误，请重新输入： ") sex = input("请输入性别：（男/女） ") while sex != "男" and sex != "女": sex = input("输入错误，请重新输入： ") room_no = input("请输入房间号： ") while room_no.isdigit() != True: room_no = input("输入错误，请重新输入： ") tel = input("请输入电话：") while tel.isdigit() != True: tel = input("输入错误，请重新输入： ") stu = [num, name, sex, room_no, tel] stu_info.append(stu) print("添加"+num+"成功") show_all_students函数def show_all_students(): for i in range(len(stu_info)): table.add_row(stu_info[i]) print(table) 主函数def main(): while True: print("*"*50) print("欢迎使用【宿舍管理系统】") print("1.查找学生") print("2.新增学生") print("3.显示全部") print("0.退出系统") print("*"*50) print() instruct = input("请选择希望执行的操作：") if instruct == "1": search_stu() elif instruct == "2": add_stu() elif instruct == "3": show_all_students() elif instruct == "0": print("欢迎再次使用【宿舍管理系统】") break else: print("输入错误，请重新输入指令！") 执行结果功能2. 录入学生信息 功能3.显示所有学生信息 功能1. 根据学号或姓名进行查找 根据学号查找 根据姓名查找 可见，重名的学生被查找出来 功能0. 退出系统 错误处理]]></content>
      <categories>
        <category>数据科学导论</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[口译英语学习笔记（2）]]></title>
    <url>%2F%E5%8F%A3%E8%AF%91%E8%8B%B1%E8%AF%AD%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%882%EF%BC%89%2F</url>
    <content type="text"><![CDATA[李平老师说，这门选修课即使选的人再少她也会坚持讲下去。因为组建口译班是她一直想做的事，现在她一定要实现自己的这个梦想。选这门课的同学里有一个东营的小姐姐，理想是去做同传，并且现在正在着手准备相关的考试。希望她们都可以实现自己的理想。坚持做自己喜欢的事情是一定是有意义的，因为至少以后回想起来不会后悔。 Chap2. 关于记忆 -- Gains -- 记忆的分类 immidiate memory - 启动注意 short-term memory - 信息处理（对口译非常重要） long-term memory 后台处理 Technics Visualization Logical restructing Time Sequence Put yourself in Emotion -- Problems -- 对细节记忆不准确；在对较长的内容进行记忆时容易走神，后半段都会忘掉；对专业相关的内容记忆会更加准确；听力不好。 -- Solutions -- 训练长时间集中注意力；训练听力]]></content>
      <categories>
        <category>口译英语</category>
      </categories>
      <tags>
        <tag>口译</tag>
        <tag>记忆</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记和李京老师的一次面谈]]></title>
    <url>%2F%E8%AE%B0%E5%92%8C%E6%9D%8E%E4%BA%AC%E8%80%81%E5%B8%88%E7%9A%84%E4%B8%80%E6%AC%A1%E9%9D%A2%E8%B0%88%2F</url>
    <content type="text"><![CDATA[内省不疚，夫何惧何忧？ ——《论语·颜渊》 针对今年微·职招新和“书与咖啡”项目的一系列问题，我们中午约了李京老师谈话。和李京老师的每次讲话我能收获到的信息量都是非常巨大的，这也让我意识到自己的一个很大的问题——思考深度不足。从大一开始，我们要求每日自省，完成感悟。可是我的感悟依然仅仅停留在“记录”和“摘抄”的层面，很多书评和影评的观点也都是受到了其他评论人的影响。自己产出新锐一手观点的能力非常差。我想这也是自己每次和老师以及学长学姐聊天时有醍醐灌顶的感觉的原因——自己思考深度不足，面对来自前辈们更加深刻的观点的时候，自己就会感觉他们的观点和想法很深刻。 下面对这次面谈做一个简单的记录。 关于招新的相关事宜 李老师跟上级报备，决定在信息门户发布通知或者是在2019级导员群中发布通知，我们向李老师提供官方报名通道之后，消息传达到同学们手中仅需要两三天。 招新时间为9月23日到10月23日，先让18级小伙伴们得到训练，再进行官方渠道的招新宣传。 关于场宣的问题，通过职协的名义招新，与其他社团一起。“枪打出头鸟”，我们只需要做好自己内部的氛围就可以了。 关于感悟Q：小伙伴们写感悟不积极，怎么办？A：通过观察，可以看出来18级以上的小伙伴们写感悟的质量还是很高的，但是对于18级的小伙伴，要么不写感悟、要么每天只是进行一个打卡。你们应该先在自己的身上找问题，问问自己是否已经做到完美。并非大家不配合，而是我们自己没有继续向18级的小伙伴们灌输感悟的意义了。Ponder：在与学长学姐们的交流中我们也可以感觉到，这一年我们和18级之间的交流太太少了。导致有特别多的想法和文化观念我们无法向18级传达，也就忽视了向他们传达感悟的意义。在此，我想自己先思考一下，每日感悟对我自己有什么意义。我们都听过一句话叫“失去了才知道珍惜。”关于感悟的意义，我们可以从这个角度去分析。在我的大二下学期，我做过一个非常有意思的尝试。那时候的我沉迷于手游无法自拔，于是我想到一个比较极端的解决方法——每天把手机留在宿舍里，早晨起床就离开宿舍。结果我坚持了不到半天就罢休了。上课的时候没法看是哪间教室、课上下载课件还得打开电脑、走在路上没法听歌听书等等一系列不便。我也是通过这件事情明白了手机在我日常的生活中起到了怎样的作用。但是现在可能很多人都没法通过“失去感悟”这件事情来知晓感悟的价值，因为大家好像没有真正的“拥有过”感悟，所以觉得不写感悟好像从来没有影响过自己的生活。我们现在来仔细思考感悟的意义。从一个最功利的角度说起：李京老师接触过无数的本科毕业生，他问大家：“你的大学生涯有没有什么一件可以拿出来吹牛的事情？”基本所有人的回答都是“没有。”大家都没有做过什么“没有第二个人做过的事情。”而感悟就是这样一件让你可以吹牛的谈资，当HR听到你说你的大学四年完成了“40万字感悟”的时候，他们的眼睛都在发亮，他们都对此非常好奇。这是很多学长学姐屡试不爽的一个面试经验。 当然这个例子对我们的启发不仅仅是感悟，我们要仔细想想，当大学四年结束时，我能不能自豪地说出一件“值得吹牛”的事情。 再来，就是利用我前面所说的“失去感悟”的方法来探寻它的价值。我大一一年的感悟完成质量还是很高的，我的每天都记录下来了，我读过的书、去过的地方、学过的东西、看过的电影都存在于我的感悟里，我回去看的时候能够确定地告诉自己，我这一年一直没有过停止进步。但是现在的我回去看我的大二时光，我发现了自己的生活里有一大片空白，我根本想不起来我这些日子是怎样度过的。我会想，“多可惜啊，如果我那时候仅仅是记录自己一天都干了什么也好啊。”这个时候，我体会到了“失去感悟”带给我的影响，我发现我的一大段时间都是空白的，这让我非常可惜。 我们做任何事情的时候都喜欢去思考事情的意义，当然这不一定是正确的做法，有时候做没有意义的事情也是很好的事情。比如说，我去做志愿，我能获得什么意义呢？我可以拥有志愿时长、可以拥有德育分，我为了它们我去做志愿。有时候我去做了没有志愿时长的志愿活动，这时候我会发一条朋友圈“不为其他，只为世上的每个人都能得到温暖。”这时候我得到了什么意义呢？我得到了虚荣心和满足感，得到了比那些“为了德育分去做志愿的同学”更多的优越感，得到了老师和同学们眼中的一个优秀人设。但是这些都太浅了，就像是我写感悟是为了积累字数、方便我去面试，为了我以后拥有更多的谈资。但这些并非是我们写感悟的最终意义，我们写感悟的最终意义，是养成“日参省乎己”的习惯。这是我眼中的感悟的最终的意义，——不仅仅是记录、不仅仅是摘抄、不仅仅是记录别人的观点，而是通过我们普通的生活去挖掘更深层的意义，学会深度思考。这和我们微·职“修炼内功”的思维是很类似的。为了达到这个目的，我还有很长的路要走。 关于“书与咖啡”合伙人参与不积极李京老师还是说，先找自身的问题。当我第一眼看到这次书与咖啡的通知时，没有想要参与的欲望。原因是什么？“港独”和我自己有什么关系？讨论政治我没兴趣啊。我为什么要花时间在与自己不相干的事情上？有这些时间为什么不去做一些更重要的事情？书与咖啡的宗旨是“务虚”，目标是让大家（合伙人）拥有更宏观的“格局”。我们不应该往下看，而是应该往上看。这世界上我们看到的东西，都能够衍生成和我们自己有关的事情。 月亮和我们有什么关系？中秋节，吃月饼，月球的潮汐与女性生理期还有关系，等等。 9月14日，沙特石油巨头企业沙特阿拉伯国家石油公司（以下简称：沙特阿美）的两处石油设施（一家炼油厂和一座油田）在受到无人机攻击后起火。这和我们有什么关系？你爸妈不开车？油价受到怎样的影响？最终怎样影响到我们自己的生活？ 我们应该从这样的宏观纵向角度去思考问题。而现在的我们大多数情况下在面对新闻的时候，都仅仅是获得新闻信息，简单的评论新闻。比如这次的港独主题，我就只会感慨愤青的差劲，不会联想这些事情对于我自身会产生怎样的影响。这样的思考方式都是孤立事件。我们要学会把事情都联系起来。 对于香港问题，我们就可以从政府、社会、个体层面去思考问题。比如从香港大学生切入，这个角度就会让大家有身份认同感。 这样的宏观纵向思考方式还需要进一步的养成。 做事情先找内因，再找外因。]]></content>
      <categories>
        <category>参省乎己</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[数据库系统原理学习笔记（2）]]></title>
    <url>%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%882%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Chap2. Introduction to the Relational Model(关系模型介绍) 本章最好通过举例来理解定义。 Introduction to Chapter 2Relational data model relational data structure (syntax)语法 integrity constraints (semantic) 完整性约束（语义） constraints on attributes of schemas, e.g. value domain, type constraints on dependencies among attributes of a schema constraints on dependencies among attributes of different schemas operations on the model 2.1 Structure of Relational Databases（关系数据库）attributes(or columns)tuples(or rows) Basic structures关系（relation）定义为：一系列域上的笛卡尔积的子集。Attributes ：$A_1, A_2, … ,A_n$domain of relation’s attributes $D_1, D_2,…D_n$ 1. relation r in DBS is the limited set. 2. attributes are non-ordered. 3. tuples' order is irrelevant. 4. `null` is a member of every domain. ![](https://s2.ax1x.com/2019/09/18/nT1rcD.jpg) A domain is atomic if its elements are considered to be invisible. 2.2 Database schema(数据库模式)Relation schema 关系模式 For attributes $A_1, A_2, … , A_n, R=(A_1, A_2, …, A_n)$ is a relation schema.e.g. Instructor-schema = (ID, name, depart_name, salary) $r(R)$ is a relation on the relation schema $R$e.g. customer(customer-name, customer-street, customer-city) on Customer-schema relation instance与relation不作区分。 an element $t$ in set $r$ is a tuple, represented by a $row$ in a table. $t[A_i]$ = the value of $t$ on the attribute $A_i$. e.g. t2[customer-name] = Smith 2.3 Keys(键，码) super key - can be used to identify uniquely a tuple in the relation.能用来被区分不同的元组。 candidate key（候选码） 候选码是最小的超码。 Primary key: A relation may have several candidate keys. Primary key is chosen as principal means to identify tuples. Primary attributes //non-primary attributes foreign key&amp;referencing relation &amp; referenced relation这里比较容易混，注意看定义。 Def. If X is one or more attributes in relation r1, and X is also the primary-key of another relation schema r2.X is called a foreign key from r1 referencing r2 X是由r1参照/关联r2的外键r1 is called the referencing relation of the foreign keyr2 is called the referenced relation of the foreign keye.g. dept_name in instructor-schema and department-schema, dept_name in instructor is a foreign key from instructor referencing department. schema diagram(模式图)、node、directed arc Referential integrity constraint(参照完整性约束)：在参照关系中，任意元组在特定关系中的取值必然等于被参照关系中某个元组在特定关系上的取值。 2.5 Query language(查询语言)procedural 过程化的：用户指导系统对数据库执行一系列操作以计算所需结果。non-procedural 非过程化的：用户只需描述所需信息，而不用给出获取该信息的具体过程。 2.6 basic relation algebra operations 基本关系运算 Select Operation - selection of rows(tuples)$\sigma_p(r)$ Project Operation将元组投影到某些属性上$\prod_{A_1, A_2, …A_k}(r)$筛选后还要去重 Union Operation$\bigcup$$r, s$ must have the same arity(元)compatible(相容的)多个操作的组合运算（查看例题） Set Difference Operation$r - s$ Set Intersection Operation$r \bigcap s$ Cartesian-Product Operation(笛卡儿积运算) Natural Join$\bowtie$自然连接运算首先形成它的两个参数的笛卡儿积，然后基于两个关系模式中都出现的属性上的相等性进行选择，最后还要去除重复属性。 Renaming Operation Compositon of OperationsChap.6 Formal Relational Query Language6.1 Relational AlgebraFundamental operations第二章都讲过了。详见下节课的笔记吧。]]></content>
      <categories>
        <category>数据库系统原理</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[机器学习课堂笔记（2）]]></title>
    <url>%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%A0%82%E7%AC%94%E8%AE%B0%EF%BC%882%EF%BC%89%2F</url>
    <content type="text"><![CDATA[机器学习的第二次课程。感觉新专业课程安排的不够合理，有很多机器学习的先修课程都在和机器学习同时进行。🤦‍♂️ Anyway,努力学习吧。 在本次课程中还没有做到的事： 1. 多查看笔记里的概念类内容，作到掌握。 2. 近一步理解笔记里出现的公式。 3. 对机器学习历史里出现的算法做进一步了解。 4. 对笔记里提到的算法进行各种实践！只有理论不可以的。🙌 第二次上课复习 Def of Machine LearningA compute program is said to learn from experience E with respect to same task T and some performance measure P, if its performance on T, as measure by P, improves with experience E. 假设用$P$来评估计算机程序在某任务$T$上的性能，若一个程序通过利用经验$E$在$T$上获得性能改善，则我们就说该程序对$E$进行了学习。 机器学习的模型分类 归纳学习：从样例中学习。 机械学习：死记硬背式学习。 进化学习、强化学习：在问题求解和规划中学习。 类比学习（如迁移学习）：通过观察和发现学习。 示教学习（如机器人模仿人的动作）：从指令中学习。 Tips:进化学习来源于达尔文的进化理论，遗传算法是进化学习的经典方法。 一个非常优秀的机器学习资源网址(还未仔细查看) 本节课的主要内容 以监督学习为例，谈一下学习的策略和学习的算法。 机器学习的发展史 几何模型 机器学习系统构成的要素 任务：可通过机器学习解决的问题。 特征：适用于样本集合中任意实例的度量方法。 模型：从数据中学习以便解决给定任务的系统方法。 学习算法的核心策略 + 求解算法一些基本概念： 损失函数 期望损失：损失函数的期望 （理论上存在，但是很难利用它） 打公式真的麻烦死了😡，公式都直接用图片好了 经验风险（又称“经验损失”） 模型关于训练样本的平均损失。根据大数定律，当样本的容量趋于无穷大时，经验损失无限趋近于期望损失。 策略1：经验风险最小化可以用此公式推导$f(x)$当样本小或者取样有问题的时候容易出现过拟合。 策略2：结构风险最小化加入正则化项，使模型不要太“特例”，避免过拟合。 求解算法：机器学习的学习算法本质上是一个优化问题求解算法。 至此，机器学习的概念已经全部结束。机器学习能干什么？列出四五个机器学习的分类，不同的分类下面能列出3.4个机器学习的算法，不同的模型怎样度量自己的风险。 机器学习的发展详见博客地址classic alg 黄色的点是基于神经网络 机器学习的历史：（上课随便记了一点，不重要的）详细资料：机器学习的历史 1949年，Hebb提出了神经心理学学习范式，这为以后的神经网络奠下基础。 1957年，Rosenblatt提出了感知器算法，是神经网络的基础。 1995年，Vapnik和Cortes提出的支持向量机（网络）（SVM） 不一定所有模型都套用深度学习，有很多其他解决问题的模型。 从样例中学习： 符号主意——“对智能行为的符号化建模”。概念学习的结果可以是显性的。 连接主意——基于神经网络。效果更好，但是知识是隐性的。 统计学习——基于数据构建概率统计模型并运用模型对数据进行预测分析。 深度学习——深度学习缺乏严格的理论基础，但是显著降低了应用者的门槛。学习深度学习的时候关心一下开源的软件。 第二章、几何模型任务、模型、策略、算法有一些数据的几何特征，如直线、曲线、平面、距离等，有助于我们区分样本的分布特征。利用几何特征构建的机器学习模型，我们称之为几何模型。几何模型主要包括线性分类器、支持向量机、最近邻算法以及K均值聚类等。 线性分类问题如果存在某个线性决策面能够将两类样本分离，则称所给数据集是线性可分的。 基本线性分类器体现了经验风险最小化。 Fisher线性分类器 基本原理：找到一个最合适的投影轴，使两类样本在该轴上的投影之间的举例尽可能远，而每一类样本的投影尽可能紧凑，从而使分类效果最佳。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>几何模型</tag>
        <tag>线性分类</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[口译英语学习笔记（1）]]></title>
    <url>%2F%E5%8F%A3%E8%AF%91%E8%8B%B1%E8%AF%AD%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89%2F</url>
    <content type="text"><![CDATA[口译英语课程，周四晚，李平老师。周四对我来说是另一种意义上的“辛苦”的一天。上午要上男神的Linux，下午网球、健身房，晚上还有口译训练。口译是非常辛苦的过程，老师说她原先翻译一天整个人神经紧张到无法松弛下来了，听到别人说话就想翻译。 比较幸运的是，选这门课的人还不到十个人，所以每个人训练的机会都很多，希望能通过这门课程提高自己的口语和听力能力吧。 Gains:Knowledge Points 大学四年学生说法：大一 freshman大二 sophomore大三 junior大四 senior 北京师范大学 Beijing Normal School中国政法大学 China University of Political Science and Law工商管理硕士 MBA Master of Business Administration 研究生 postgraduates本科生 undergraduates Give birth to 生了…Intensive reading 精读 Tips：翻译时如果不确定可以只翻译中心词 Archery 射箭场Oral English 口语爱情长跑 love marothon（马拉松）Middle schoolers 中学生大约400 400 about早产儿 premature有时我绘画。 Seldom I draw.硕士研究生 master candidate长足的进步 leap forward谢谢我的翻译者。 Thanks for my interpreter.摇滚乐 rock and roll电子乐 electronic music消除隔阂、缩短差距 Bridge the gap“联络口译” liason interpreting同传箱 boothCoordinate 使协调，使相配合These shade coordinates with a wide range of other colors. 这种深浅的颜色可以与很多其他颜色搭配。不管怎么说我饿了。 I’m hungry anyway.Give me a break. 别说了。 Tips: 翻译时候要有自信。 初级英语口译70%: Quizzes, presentation, assignment30%: 期末考察 Basic conceptTranslation. Written translation 笔译Oral translation 口译 交传 consecutive 同传 simultaneous 视阅口译 sightInterpretation 一般不用这个词做“口译”，因为它大多数代表“解释”的意思。Interpreting 翻译的方法Literal: word for word 直译纸老虎 paper tiger一国两制 one nation two systems君子协定 gentleman’s agreement武装到牙齿 armed to the teeth Free 意译我铁石心肠。 I’m so hard.我难以接近。 I’m so difficult.我还想问你呢？ You have stolen my questions.秃子头上的虱子——明摆着。 It’s as plain as your nose in your face.胳膊拧不过大腿。 Little fish does not eat big fish. 口译的原则准、顺、快 口译员的素质： 对语言熟练，口语熟练 知识 “百科全书” 思维 技能 Problems:词汇量差的太多，无论是中译英还是英译中脑子都会断片。很多词仅仅是认识，但是不会用起来。 Solutions：注意词汇学习的深度，学会运用。]]></content>
      <categories>
        <category>口译英语</category>
      </categories>
      <tags>
        <tag>口译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据科学导论学习笔记（1）]]></title>
    <url>%2F%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E5%AF%BC%E8%AE%BA%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89%2F</url>
    <content type="text"><![CDATA[数据科学导论作为数据科学与大数据技术专业的导论课程具有相当重要的意义。每周4课时（提前结课），授课教师石川老师。 希望新学期的自己能够积极完成每一门课程的课后复习和拓展，认真写博客整理知识点。 Chap.1 数据科学概论课程性质:一门导论性质的课程；包含理论知识和案例分析先修课程:高等数学，线性代数，概率论，数据结构，算法导论，计算机组成原理等后继课程:数据挖掘，数据库，机器学习，深度学习，大数据分析等 1.1 数据和大数据1.1.1 数据数据的定义:从数据科学的角度，将数据定义为，在一定背景下 有意义的 对于现实世界中的事物定性或定量的记录。数据的类型: 依据结构分类 :结构化数据：如数字、字符、日期等等属于结构化数据类型；非结构化数据：文字、图片、视频、音频等； 依据形式分类 :文本、数字、声音、图片等 依据来源分类:观测数据和实验数据 数据的DIKW模型:DIKW模型通常也被称为知识金字塔，是一个金字塔状的层状模型。Data, Infomation, Knowledge, Wisdom 1.1.2 大数据大数据的定义:1998年的 USENIX 大会上，美国硅图公司的首席科学家 John R.Mashey 首次提出了“大数据”这一概念，发表了名为《大数据与下一次基础设施压力的浪潮》的报告。首先，大数据依旧是数据，或数据相关的过程；其次，大数据的规模并非一定要达到某一确切的数值，关键在于，是否超过了实际情况下的数据存储能力和数据计算能力。 大数据相关定理与模型:（1）5V模型多样性（ Variety ），大量性（ Volume ），高速性（Velocity），价值性（ Value ），真实性（Veracity） （2）5R模型从数据管理的角度认识从大数据中获取有用信息的过程。该模型包括大数据的相关特性（Relevant），实时特性（Realtime），真实特性（Realistic），可靠特性（Reliable），以及投资回报特性（Return on investment, ROI）值得注意的是5R模型中的投资回报（ROI）。许多的大数据项目最初关注的重点只是数据本身的利用，而没有认识到对数据的利用怎么与整个商业计划相适应，忽略了数据之下的知识的价值。 （3）4P模型在医疗大数据的环境中产生了医学4P模型，包含预测性（Predictive），预防性（Preventive），个体化（Personalized），参与性（Participatory）。该医疗模型基于大数据，对疾病做出预测，并基于个人数据对病人做出个性化的服务，同时，诊疗过程中的数据将再次被记录到数据库中，从而为病人提供基于大数据的健康建议。 （4）HACE定理用于阐述大数据的定理HACE定理将大数据描述为，始于异构（Heterogeneous）,自治（Autonomous）的多源海量数据，旨在寻求探索复杂的（Complex）和演化的（Evolving）数据关联的方法和途径。基于HACE定理，文章还提出了大数据处理的三层框架。 框架的第一层是大数据的计算平台。 框架的第二层是大数据的语义和应用知识，包含数据共享与隐私、领域和应用知识的问题。 框架的第三层是大数据分析算法。 1.2 数据科学理论基础1.2.1 数据科学发展历程仅记录几个时间节点 1974年，图灵奖获得者 Peter Naur 首次提到了“数据科学”的概念。 2002年，CODATA创立了学术期刊&lt; Data Science Journal &gt;，这是首个关于数据科学的学术期刊。 2009年，谷歌首席经济学家Hal Ronald Varian发表意见称，未来十年最性感的工作是统计学家。 2010年，作家Kenneth Cukier 在《经济学人》中发表特别报告提出，“数据科学家作为一种新的职业出现，他们具备了软件程序员，统计学家和讲故事者的技能，用来提取大量数据背后隐藏的规律” 2010年，Drew Conway在文章中指出，“能够胜任工作的数据科学家需要学习很多方面东西”，并将其以韦恩图的形式总结为黑客技能、数学和统计学知识、以及专业领域知识。 1.2.2 数据科学的主要内容研究内容和研究对象:现实世界中来源不同类型不同的数据。 理论体系: Hacking skill：计算机科学、人工智能等方面的方法和技术。Math&amp;Statistics Knowledge：数学和统计学方法理论。Substantive Expertise：实质性领域知识。 数据科学与第四范式:2007年图灵奖得主 Jim Gray 在演讲中提出了“指数级增长的科学依据”背景下的数据密集型科学研究的第四范式。 几千年前，科学的星星之火刚刚点燃时的实验科学范式； 几百年前以牛顿的经典力学，麦克斯韦理论解释的电磁学，所代表的理论科学范式 几十年前的计算机科学范式 到信息爆炸的今天，我们需要从计算机科学中把数据密集型科学区分出来，作为一个新的、科学探索的第四种范式，这就是第四范式的由来。数据密集型范式 国际数据委员会（CODATA）原称国际科技数据委员会，是原国际科学联合会下属一级学术机构，其宗旨是推动科技数据应用，发展数据科学，促进科学研究，造福人类社会，成立于1966年，秘书处设在法国巴黎。国际科学联合会和国际社会科学联合会于2018年7月正式合并成为International Science Council (ISC)，国际科技数据委员会也相应更名为国际数据委员会，从ICSU下一个专门关注科学数据的跨学科的国际组织演变成ISC下推动大数据与数据科学发展的主要机构。 数据密集型科学由三个基本活动组成：数据采集、数据管理和数据分析。 数据科学与第四范式的联系在于，这两者是大数据研究的两大理论基础，前者是更广泛意义上的数据科学，后者是针对科学研究范式而言的。 1.3 数据科学应用实践1.3.1 数据科学家数据科学家的定义: 具有计算机科学技术，数学和统计学知识基础和实质性专业理论知识的人。 能够发现现实世界的问题，收集问题相关的数据，抽取数据中的信息，并解释数据背后的意义的人。 数据科学家的技能: 数据科学家的工作需要使用：Python, R, SQL, Hadoop, Spark, Java, SAS, C++, Tensorflow等语言、库或是工具。 1.3.2 数据科学工作流程 分析数据包括两步，第一步是探索性分析，第二步是通过机器学习算法和统计学模型对数据进行分析。探索性分析是指对已有的数据在尽量少的先验假定下进行探索，通过制图，制表，方程拟合等手段探索数据结构和规律的一种数据分析方法，适用于面对大量数据不知如何下手从何处分析的情况。 1.3.3 数据科学实践案例 医疗健康大数据 沃尔玛与社交大数据 大数据与智慧城市]]></content>
      <categories>
        <category>数据科学导论</category>
      </categories>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mdtst]]></title>
    <url>%2Fmdtst%2F</url>
    <content type="text"><![CDATA[自动保存tst 这是文字 上面是分割线 上面是空行 文件位置：/images/tst.pyimport csv+ import numpy as np- import numpy links, formatting, and tags supported list syntax required (any unordered or ordered list supported) this is a complete item this is an incomplete item Do not just seek happiness for yourself. Seek happiness for all. Through kindness. Through mercy. David LevithanWide Awake Your browser does not support the audio tag. 欢迎 内容 内容 内容 已完成 未完成 primary, info, success, warning, danger, info 已完成 未完成 普通 变大 33% 两倍大 warning 人生乃是一面镜子，从镜子里认识自己，我要称之为头等大事，也只是我们追求的目的！ 首页 ---]]></content>
  </entry>
  <entry>
    <title><![CDATA[新博客的第一篇文章]]></title>
    <url>%2Fnewpapername%2F</url>
    <content type="text"><![CDATA[欢迎]]></content>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post$ hexo new "My New Post" More info: Writing Run server$ hexo server More info: Server Generate static files$ hexo generate More info: Generating Deploy to remote sites$ hexo deploy More info: Deployment]]></content>
  </entry>
  <entry>
    <title><![CDATA[「迁移学习简明手册」学习笔记（1）]]></title>
    <url>%2F%E3%80%8C%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%AE%80%E6%98%8E%E6%89%8B%E5%86%8C%E3%80%8D%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89%2F</url>
    <content type="text"><![CDATA[1.迁移学习的基本概念1.2 迁移学习基本概念 核心问题：找到新问题和原问题之间的相似性，才可以顺利地实现知识的迁移。 定义：迁移学习，是指利用数据、任务、或模型之间的相似性，将在旧领域学习过的模型，应用在新领域的一种学习过程。 1.3 为什么要迁移学习这个表格包括了1.3的所有内容，可以只看这个表格： 1.大数据与少标注之间的矛盾 2.大数据与弱计算之间的矛盾 3.普适化模型与个性化需求之间的矛盾机器学习的目标是构建一个尽可能通用的模型，而人们的个性化需求五花八门，短期内根本无法用一个通用的模型去满足。 4.特定应用的需求推荐系统的冷启动问题：一个新的推荐系统，没有足够的用户数据，如何进行精准的推荐；一个崭新的图片标注系统，没有足够的标签，如何进行精准的服务？ 针对以上问题，迁移学习是如何解决的呢？ 1.迁移数据标注 2.模型迁移（将那些大公司在大数据上训练好的模型，迁移到我们的任务中） 3.自适应学习（对普适化模型进行灵活的调整，以便完成我们的任务） 4.相似领域知识迁移 1.4 与已有概念的区别和联系1.迁移学习和机器学习迁移学习属于机器学习的一类 2.迁移学习和多任务学习多任务学习指多个相关的任务一起协同学习。 3.迁移学习和终身学习终身学习是在已经学习好若干个任务之后，面对新的任务可以继续学习而不遗忘之前学习的任务。 4.迁移学习和领域自适应5.迁移学习和增量学习增量学习侧重解决数据不断到来，模型不断更新的问题。 6.迁移学习和自我学习自我学习指的是模型不断地从自身处进行更新 7.迁移学习和协方差漂移协方差漂移指数据地边缘概率分布发生变化 1.5 负迁移（“东施效颦”）如果两个领域之间不存在相似性，或者基本不相似，那么就会大大损害迁移学习地效果。这时候，我们可以说出现了==负迁移(Negative Transfer)== 定义：在源域上学习到的知识，对于目标域上的学习产生负面作用。 产生负迁移的原因： 数据问题 方法问题：源域和目标域是相似的，但是迁移学习的方法不够好。 传递迁移学习：传统迁移学习好比是踩着一块石头过河，传递迁移学习就是踩着连续的两块石头。当两个领域不相似时，传递迁移学习却可以利用处于这两个领域之间的若干领域，将知识传递式的完成迁移。 2.迁移学习的研究领域机器学习可分为有监督、半监督和无监督的机器学习三大类。迁移学习也可以进行这样的分类。 分类的四个准则：按目标域有无标签分、按学习方法分、按特征分、按在线形式分 2.1 按目标域标签分 1.监督迁移学习 Supervised Transfer Learning 2.半监督迁移学习 Semi-Supervised Transfer Learning 3.无监督迁移学习 Unsupervised Transfer Learning 显然，少标签或无标签的问题（半监督和无监督迁移学习），是研究的热点和难点。 2.2 按学习方法分类 1.基于样本的迁移学习方法(Instance based Transfer Learning)通过权重重用，对源域和目标域的样例进行迁移 2.基于==特征==的迁移学习方法(Feature based Transfer Leaning)意思是说，假设源域和目标域的特征原来不在一个空间，或者说它们在原来那个空间上不相似，那我们就想办法把它们变换到一个空间里面，那这些特征不就相似了？ 3.基于==模型==的迁移学习方法(Model based Transfer Leaning)构建参数共享的模型 4.基于关系的迁移学习方法(Relation based Transfer Learning)挖掘和利用关系进行类比迁移 2.3 按特征分类 1.同构迁移学习(Homogeneous Transfer Learning) 2.异构迁移学习(Heterogeneous Transfer Learning)如果特征语义和维度都相同，那么就是同构；反之，如果特征完全不相同，那么就是异构。举个例子来说，不同图片的迁移，就可以认为是同构；而图片到文本的迁移，则是异构的。 2.4 按离线与在线形式分 1.离线迁移学习(Offline Transfer Learning) 2.在线迁移学习(Online Transfer Learning) 目前，绝大多数的迁移学习方法，都采用了离线方式。即，源域和目标域均是给定的，迁移一次即可。这种方式的缺点是显而易见的：算法无法对新加入的数据进行学习，模型也无法得到更新。与之相对的，是在线的方式。即随着数据的动态加入，迁移学习算法也可以不断地更新。 3.迁移学习的应用计算机视觉、文本分类、行为识别、自然语言处理、室内定位、视频监控、舆情分析、人机交互 3.1 计算机视觉同一类图片，不同的拍摄角度、不同光照、不同背景，都会造成特征分布发生改变。因此，使用迁移学习构建跨领域的鲁棒分类器是十分重要的。 3.2 文本分类由于文本数据有其领域特殊性，因此，在一个领域上训练的分类器，不能直接拿来作用到另一个领域上。这就需要用到迁移学习。例如，在电影评论文本数据集上训练好的分类器，不能直接用于图书评论的预测。这就需要进行迁移学习。 3.3 时间序列行为识别 (Activity Recognition) 主要通过佩戴在用户身体上的传感器，研究用户的行为。行为数据是一种时间序列数据。不同用户、不同环境、不同位置、不同设备，都会导致时间序列数据的分布发生变化。 3.4 医疗健康医疗领域研究的难点问题是，无法获取足够有效的医疗数据。 4.基础知识4.1迁移学习的问题形式化4.1.1 领域领域(Domain)是进行学习的主体。领域主要由两部分构成：数据和生成这些数据的概率分布。源领域：有知识、有大量数据标注的领域；目标域：我们最终要赋予知识、赋予标注的对象。 4.1.2 任务任务(Task)：学习的目标。由两部分组成：标签和标签对应的函数。 4.1.3 迁移学习领域自适应(Domain Adaptation) 4.2 总体思路开发算法来最大限度地利用有标注地领域地知识，来辅助目标领域的知识获取和学习。找到相似性 (不变量)，是进行迁移学习的核心。度量工作的目标有两点： 一是很好地度量两个领域的相似性，不仅定性地告诉我们它们是否相似，更定量地给出相似程度。 二是以度量为准则，通过我们所要采用的学习手段，增大两个领域之间的相似性，从而完成迁移学习。 一句话总结： ==相似性是核心，度量准则是重要手段。== 4.3 度量准则核心：衡量两个数据域的差异。 4.3.1 常见的几种距离 1.欧式距离 2.闵科夫斯基距离 3.马氏距离 4.3.2 相似度 1.余弦相似度 2.互信息 3.皮尔逊相关系数 4.Jaccard相关系数 4.3.3 KL散度与JS距离4.3.4 最大均值差异MMD(Maximun mean discrepancy)4.3.5 Principle Angle4.3.6 A-distance4.3.7 Hilbert-Schmidt Independence Criterion4.3.8 Wasserstein Distance4.4 迁移学习的理论保证这一部分有些难度。当自己提出的算法需要理论证明时，可以借鉴这一部分。 5.迁移学习的基本方法四种基本方法：基于样本的迁移，基于模型的迁移，基于特征的迁移，以及基于关系的迁移。 5.1 基于样本的迁移学习方法(Instance based Transfer Learning)如图，在迁移时，为了最大限度地和目标域相似，我们可以人为地提高源域中属于狗这个类别地样本权重。优缺点：虽然实例权重法具有较好的理论支撑、容易推导泛化误差上界，但这类方法通常只在领域间分布差异较小时有效，因此对自然语言处理、计算机视觉等任务效果并不理想。 5.2 基于特征迁移通过特征变换的方式互相迁移，来减少源域和目标域之间地差距；或者将源域和目标域的数据特征变换到统一特征空间中，然后利用传统的机器学习方法进行分类识别。根据特征的同构和异构性，又可以分为同构和异构迁移学习。这类方法通常假设源域和目标域间有一些交叉的特征。 5.3 基于模型学习基于模型的迁移方法 (Parameter/Model based Transfer Learning) 是指从源域和目标域中找到他们之间共享的参数信息，以实现迁移的方法。这种迁移方式要求的假设条件是：源域中的数据与目标域中的数据可以共享一些模型的参数。 5.4 基于关系迁移这种方法比较关注源域和目标域的样本之间的关系。这些文章都借助于马尔科夫逻辑网络 (Markov Logic Net)来挖掘不同领域之间的关系相似性。我们将重点讨论基于特征和基于模型的迁移学习方法，这也是目前绝大多数研究工作的热点。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>迁移学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于链接内容的社区发现算法（一）]]></title>
    <url>%2F%E5%9F%BA%E4%BA%8E%E9%93%BE%E6%8E%A5%E5%86%85%E5%AE%B9%E7%9A%84%E7%A4%BE%E5%8C%BA%E5%8F%91%E7%8E%B0%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Robust Detection of Link Communities in Large Social Network by Exploiting Link SemanticsZHOU YUYANG Robust Detection of Link Communities in Large Social Network by Exploiting Link Semantics 这篇论文是我加入张老师实验室读的第一篇论文，寒假里草草读了一遍，感叹了自己垃圾的英文水平，上周除了上课和作业基本没做什么，一直在研读这篇论文。很幸运的是上周关于这篇论文的汇报我做的非常精彩，也不枉自己上周那么辛苦的肝了。 这篇博客用来记录自己研读时候的思考和整理。 整个论文的整体内容我将从四个方面介绍。分别是社区发现算法的背景和现存的方法、论文提出的模型和方法、试验和结论与讨论。 1. Background 1.1 社交网络的发展 社交对于世界各地各领域的人们来讲都越来越重要。随着社交网络的发展，越来越多的信息开始在互联网中聚集。 对于这些大数据的分析能够让我们更加熟悉网络的深层结构、了解用户行为和未来趋势。 社交网络中的一个重要的问题便是社区发现，通过社区发现我们能够为用户提供个性化推荐和异常行为的识别。 所谓的“社区发现”，就是将出现在社交网络中的用户节点划分成不同的组别。每个组的用户结点都有着某些相同的特征。 1.2 现存的方法 我们通常用一个图来表示社交网络。其中的点表示用户结点，其中的边表示用户之间的联系。 最初人们社区发现的算法是根据网络的拓扑结构，即让我们划分后的各个社区间的边的数量最少，社区内部点之间的边尽可能的多 之后，社区发现的算法得到改进，我们通过节点内容进行社区划分，即使得同一个社区内的结点内容尽可能多的相似。通过结点内容进行社区发现能够大大提升我们社区发现的效率。 同时我们发现，用户之间的链接，即图中的边也含有大量的信息。 这张图形象的表示了我们的方法和其他方法的区别。其中右边的图是基于结点内容进行社区发现的算法示意图，左边的图是我们基于链接内容进行社区发现的图。我们可以看出现有的其他方法的问题： 1.只考虑了节点内容。考虑节点内容进行社区发现在有些时候有很高的效率。以微博用户的社区发现为例，当我们提供的内容是用户简介时，基于节点内容进行社区发现是很可以的。但是当我们提供的内容是用户之间发送的消息时，这其实是一种“链接内容”，我们需要将链接内容转换成节点内容，比如用户A发送的所有消息算成用户A的节点内容。这时候势必导致社区划分的不准确。 2.假设网络拓扑社区和结点内容社区的用户结点是一样的。两个用户间联系紧密，构成一个拓扑社区，但是他们聊天的内容可能是很五花八门的，两个人可能被分到不同的节点内容社区中去，这个时候现有的方法社区发现的效率就会下降。 3.每个社区仅仅有一个话题。比如右边的图把Music和Movies混在一起当作一个话题，而我们的方法（左边）含有两个话题。 4.仅仅用单个词汇进行社区标签。有时候我们可能会不知所云。而我们的方法用句子进行标签，便于理解。 2.The Model and Method2.1综述详见图片 2.2 详细分析我们先来看看我们进行社区发现需要考虑哪一些因素： 拓扑角度：结点、链接 内容角度：单词、句子、话题 社区和话题群聚(topic cluster) 变量介绍详见图片(难理解的内容都已经用中文进行注释) 所有变量的详细关系如下图所示 为了便于理解，我自己又画了一个图。 图左半部分就是根据拓扑结构进行社区发现，右半部分是根据节点内容进行社区发现。 现在，我们的模型已经建立起来了，我们的目标为以下三点： 具体算法我们算法的整体思想是这样的：首先我们根据某标准把网络中的所有节点划分到不同的社区中（E-step），然后我们将提取每个社区中的关键词，来进行社区标注。（M-step）我们再根据标注进行有监督的学习，对社区进行更精准的划分，以此来一遍遍迭代。 下面我们运用了极大似然的思想进行EM算法。E-step： 我们进行期望化的变量是p，p代表着链接&lt;i,j&gt;被分配到哪个社区中。现在p的取值是Jensen不等式的取等条件。 M-step： 下面我们要求式(3)的最大值，tau、 omega_ri、 y_rj都是可以通过直接求导求出来的。剩下的psai和fai的最大值我们再一次通过EM算法来求。引入变量p和h，运用JENSEN公式，p和h在取等条件时式子取到最大值。 下面我们给出整个算法的伪代码，看懂这个图整个算法的思路就差不多了。]]></content>
      <categories>
        <category>论文</category>
      </categories>
      <tags>
        <tag>社区发现</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于链接内容的社区发现算法（二）]]></title>
    <url>%2F%E5%9F%BA%E4%BA%8E%E9%93%BE%E6%8E%A5%E5%86%85%E5%AE%B9%E7%9A%84%E7%A4%BE%E5%8C%BA%E5%8F%91%E7%8E%B0%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Robust Detection of Link Communities in Large Social Network by Exploiting Link SemanticsZHOU YUYANG 这一部分没什么难点，ppt里写的都很清楚了。。 三、试验1.数据集我们选择了两个数据集，包括美国安然能源公司内部的邮件内容（安然公司丑闻，加州能源危机）和Reddit新闻网站三天的的三个论坛的内容。如果用户A对用户B的帖子进行评论，就产生了一条从A到B的链接，链接内容为评论的内容。 那么如何判断我们社区发现的结果是正确的呢？对于第一个数据集，伯克利大学的学生已经将这些用户节点分成了11个用户社区，我们可以直接将社区发现的结果与这十一个社区比对。对于第二个数据集，我们可以直接将发现的社区和三个论坛内容相比较。 2.对比的方法我们采取了8种最先进的社区发现算法，包括利用拓扑结构的、利用结点内容的、利用链接内容的、可重叠的、不可重叠的（可重叠的意思就是可以将一个用户结点放进多个社区里）等，如图： 3.测评参数F-score和Jaccard similarity，用于测评相似度的两个参数，结果两个参数越大，说明社区发现的结果越好。 4.结果 5.个例研究我们选择了Reddit网站2012年8月27号的数据集进行分析，与我们的方法对比的是SCI SCI方法的结果如下： 我们的方法： 我们的方法还有一个好处，就是可以通过fai和Y找到社区的词云： 我们方法的应用建议： 四、结论 这是文章的标题，下面我们对标题的关键词进行讨论和总结。Robust:健壮性。在传统的方法中，当网络拓朴和话题群聚不重合的时候，方法的效率就会变得很低，而我们的方法将网络拓朴和话题群聚分开来讨论，具有一定的健壮性。 Detection of Link Communities：本论文的主要内容——社区发现。 Exploiting Link Semantics: 基于链接语义。]]></content>
      <categories>
        <category>论文</category>
      </categories>
      <tags>
        <tag>社区发现</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[「机票价格预测系统」需求分析]]></title>
    <url>%2F%E6%9C%BA%E7%A5%A8%E4%BB%B7%E6%A0%BC%E9%A2%84%E6%B5%8B%E7%B3%BB%E7%BB%9F%E9%9C%80%E6%B1%82%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[最终的调研结果——我们发现了一款名叫蜻蜓旅行的app，能够基本实现我们的机票价格预测要求，这个项目最终没有进行下去。 「机票价格预测系统」需求分析周宇洋、罗钟豪20190416一、项目概况1.背景随着现代交通工具的发展和进步，越来越多的人们选择飞机出行。飞机出行具有快速方便、轻松舒适、安全可靠等优势。市场现存的购票软件为人们购票提供了极大的便利。其中同程旅游、去哪儿旅行、携程旅行、途牛旅游、飞猪旅行等购票APP占有很大的用户市场。与此同时，我们发现机票票价的浮动十分剧烈，相同时间、相同起抵地点的航班，在一周内的票价浮动能达到几百甚至上千元，很多用户对于这样浮动剧烈的票价大惑不解。于是我们想要为出行的用户提供这样一个「机票价格预测系统」，能够告知用户在什么时间点能够以满意的价格买到自己需要的机票。 2.项目愿景我们希望通过我们的价格预测系统，用户能够了解到近期机票票价的浮动情况和票余量（暂定），成功以满意的价格买到自己所需的机票。 二、数据需求我们需要飞猪旅行和携程旅行（暂定）至少两个月的机票价格和票余量（暂定），并包含起抵地点、出行时间、起飞时段、航空公司（暂定）、舱位类型、起抵机场（暂定）、机型（大型机、中型机、小型机）、乘客人数的信息。[飞猪旅行的票价刷新时长为20分钟] 三、业务功能需求我们最终的系统将由网页或微信小程序（暂定）的形式展示给用户。用户输入出行时间、起抵地点，便能获得近期该航班票价的价格预测。]]></content>
      <categories>
        <category>项目</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[爬虫入门]]></title>
    <url>%2F%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[助教说学习`Python`的最好方法是从爬虫下手🤠。正好现在导师把我分配给学姐，让我们完成一个机票价格预测系统。 但是这学期的课业太忙了😭，自己因为情感的事情状态也没有那么好，希望自己还能有足够的精力去做好这件事。💪 爬虫入门 0415一、网络爬虫概念 网络爬虫（英语：web crawler），也叫网络蜘蛛（spider），是一种用来自动浏览万维网的网络机器人。其目的一般为编纂网络索引。 网络爬虫可以将自己所访问的页面保存下来，以便搜索引擎事后生成索引供用户搜索。 来源Wikipedia 二、爬虫入门综述 “入门”是良好的动机，但是可能作用缓慢。如果你手里或者脑子里有一个项目，那么实践起来你会被目标驱动，而不会像学习模块一样慢慢学习。 另外如果说知识体系里的每一个知识点是图里的点，依赖关系是边的话，那么这个图一定不是一个有向无环图。因为学习A的经验可以帮助你学习B。因此，你不需要学习怎么样“入门”，因为这样的“入门”点根本不存在！你需要学习的是怎么样做一个比较大的东西，在这个过程中，你会很快地学会需要学会的东西的。当然，你可以争论说需要先懂python，不然怎么学会python做爬虫呢？但是事实上，你完全可以在做这个爬虫的过程中学习python :D 你需要学习 基本的爬虫工作原理 基本的http抓取工具，scrapy Bloom Filter: Bloom Filters by Example 如果需要大规模网页抓取，你需要学习分布式爬虫的概念。其实没那么玄乎，你只要学会怎样维护一个所有集群机器能够有效分享的分布式队列就好。最简单的实现是python-rq: https://github.com/nvie/rq rq和Scrapy的结合：darkrho/scrapy-redis · GitHub 后续处理，网页析取(grangier/python-goose · GitHub)，存储(Mongodb) 爬虫的原理想象你是一只蜘蛛，现在你被放到了互联“网”上。那么，你需要把所有的网页都看一遍。怎么办呢？没问题呀，你就随便从某个地方开始，比如说人民日报的首页，这个叫initial pages，用$表示吧。 在人民日报的首页，你看到那个页面引向的各种链接。于是你很开心地从爬到了“国内新闻”那个页面。太好了，这样你就已经爬完了俩页面（首页和国内新闻）！暂且不用管爬下来的页面怎么处理的，你就想象你把这个页面完完整整抄成了个html放到了你身上。突然你发现，在国内新闻这个页面上，有一个链接链回“首页”。作为一只聪明的蜘蛛，你肯定知道你不用爬回去的吧，因为你已经看过了啊。所以，你需要用你的脑子，存下你已经看过的页面地址。这样，每次看到一个可能需要爬的新链接，你就先查查你脑子里是不是已经去过这个页面地址。如果去过，那就别去了。好的，理论上如果所有的页面可以从initial page达到的话，那么可以证明你一定可以爬完所有的网页。 效率 通常的判重做法是怎样呢？Bloom Filter. 简单讲它仍然是一种hash的方法，但是它的特点是，它可以使用固定的内存（不随url的数量而增长）以O(1)的效率判定url是否已经在set中。 可惜天下没有白吃的午餐，它的唯一问题在于，如果这个url不在set中，BF可以100%确定这个url没有看过。但是如果这个url在set中，它会告诉你：这个url应该已经出现过，不过我有2%的不确定性。注意这里的不确定性在你分配的内存足够大的时候，可以变得很小很少。 进一步提高效率 另外一个瓶颈——你只有一台机器。不管你的带宽有多大，只要你的机器下载网页的速度是瓶颈的话，那么你只有加快这个速度。用一台机子不够的话——用很多台吧！当然，我们假设每台机子都已经进了最大的效率——使用多线程（python的话，多进程吧）。 我们把这100台中的99台运算能力较小的机器叫作slave，另外一台较大的机器叫作master，那么回顾上面代码中的url_queue，如果我们能把这个queue放到这台master机器上，所有的slave都可以通过网络跟master联通，每当一个slave完成下载一个网页，就向master请求一个新的网页来抓取。而每次slave新抓到一个网页，就把这个网页上所有的链接送到master的queue里去。同样，bloom filter也放到master上，但是现在master只发送确定没有被访问过的url给slave。Bloom Filter放到master的内存里，而被访问过的url放到运行在master上的Redis里，这样保证所有操作都是O(1)。 参考资料作者：谢科链接：https://www.zhihu.com/question/20899988/answer/24923424来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
</search>
