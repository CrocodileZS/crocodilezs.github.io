<!DOCTYPE html>
<html lang='zh-CN'>

<head>
  <meta name="generator" content="Hexo 5.4.2">
  <meta charset="utf-8">
  

  <meta http-equiv='x-dns-prefetch-control' content='on' />
  <link rel='dns-prefetch' href='https://cdn.jsdelivr.net'>
  <link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin>
  <link rel='dns-prefetch' href='//unpkg.com'>

  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="HandheldFriendly" content="True" >
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="theme-color" content="#f8f8f8">
  <title>KNN与Naive_Bayes代码实现 - 鳄鱼Crc2H0U</title>

  

  
    <meta name="description" content="任务要求采用Python实现分类算法：  不得借助现成的工具包调库，例如SKlearn 至少实现k-近邻，朴素贝叶斯，逻辑回归，决策树与支持向量机中的其中一个算法。k-临近，朴素贝叶斯相对较简单，逻辑回归，决策树与支持向量机相对较难。 对breast cancer数据集调用编写的函数进行分类演示。 能力强的可以多实现几种算法">
<meta property="og:type" content="article">
<meta property="og:title" content="KNN与Naive_Bayes代码实现">
<meta property="og:url" content="https://blog.crocodilezs.top/201911/KNN%E4%B8%8ENaive_Bayes%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/index.html">
<meta property="og:site_name" content="鳄鱼Crc2H0U">
<meta property="og:description" content="任务要求采用Python实现分类算法：  不得借助现成的工具包调库，例如SKlearn 至少实现k-近邻，朴素贝叶斯，逻辑回归，决策树与支持向量机中的其中一个算法。k-临近，朴素贝叶斯相对较简单，逻辑回归，决策树与支持向量机相对较难。 对breast cancer数据集调用编写的函数进行分类演示。 能力强的可以多实现几种算法">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://blog.crocodilezs.top/201911/KNN%E4%B8%8ENaive_Bayes%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/2-1.jpg">
<meta property="article:published_time" content="2019-10-25T04:32:50.000Z">
<meta property="article:modified_time" content="2022-05-23T17:19:53.132Z">
<meta property="article:author" content="CrocodileZS">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://blog.crocodilezs.top/201911/KNN%E4%B8%8ENaive_Bayes%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/2-1.jpg">
  
  

  <!-- feed -->
  
    <link rel="alternate" href="/atom.xml" title="鳄鱼Crc2H0U" type="application/atom+xml">
  

  
    
<link rel="stylesheet" href="/css/main.css">

  

  
    <link rel="shortcut icon" href="https://bu.dusays.com/2022/05/24/628bb5874996a.jpg">
  

  
</head>

<body>
  




  <div class='l_body' id='start'>
    <aside class='l_left' layout='post'>
    


<header class="header">

<div class="logo-wrap"><a class="avatar" href="/about/"><div class="bg" style="opacity:0;background-image:url(https://cdn.jsdelivr.net/gh/cdn-x/placeholder@1.0.2/avatar/round/rainbow64@3x.webp);"></div><img no-lazy class="avatar" src="/media/avatar.png" onerror="javascript:this.classList.add('error');this.src='https://cdn.jsdelivr.net/gh/cdn-x/placeholder@1.0.1/image/2659360.svg';"></a><a class="title" href="/"><div class="main">鳄鱼Crc2H0U</div><div class="sub cap">野生鳄鱼的自留地</div></a></div>
<nav class="menu dis-select"><a class="nav-item active" href="/">文章</a><a class="nav-item" href="/about/">关于</a><a class="nav-item" href="/friends/">友链</a><a class="nav-item" href="/timeline/">时间轴</a><a class="nav-item" href="https://blog.crocodilezs.top/en">English</a></nav></header>

<div class="widgets">

<div class="widget-wrap single" id="toc"><div class="widget-header cap dis-select"><span class="name">本文目录</span></div><div class="widget-body fs14"><div class="doc-tree active"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%BB%E5%8A%A1%E8%A6%81%E6%B1%82"><span class="toc-text">任务要求</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%E2%80%94%E2%80%94kNN"><span class="toc-text">算法实现——kNN</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%BA%90%E7%A0%81"><span class="toc-text">源码</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE"><span class="toc-text">导入数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#kNN%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0"><span class="toc-text">kNN算法实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%B2%BE%E7%A1%AE%E5%BA%A6%E8%AE%A1%E7%AE%97%E5%87%BD%E6%95%B0"><span class="toc-text">精确度计算函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BB%E5%87%BD%E6%95%B0"><span class="toc-text">主函数</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%E2%80%94%E2%80%94Naive-Bayes"><span class="toc-text">算法实现——Naive_Bayes</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%BA%90%E7%A0%81-1"><span class="toc-text">源码</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE-1"><span class="toc-text">导入数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E6%AF%8F%E4%B8%AA%E8%BF%9E%E7%BB%AD%E7%9A%84%E5%B1%9E%E6%80%A7%E5%88%92%E5%88%86%E5%8C%BA%E9%97%B4%E5%B9%B6%E7%BB%9F%E8%AE%A1%E4%B8%AA%E6%95%B0"><span class="toc-text">对每个连续的属性划分区间并统计个数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF"><span class="toc-text">实现朴素贝叶斯</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E7%B2%BE%E7%A1%AE%E5%BA%A6"><span class="toc-text">计算精确度</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BB%E5%87%BD%E6%95%B0-1"><span class="toc-text">主函数</span></a></li></ol></li></ol></div></div></div>


</div>


    </aside>
    <div class='l_main'>
      

      

<div class="bread-nav fs12"><div id="breadcrumb"><a class="cap breadcrumb" href="/">主页</a><span class="sep"></span><a class="cap breadcrumb" href="/">文章</a><span class="sep"></span><a class="cap breadcrumb-link" href="/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E5%AF%BC%E8%AE%BA/">数据科学导论</a></div><div id="post-meta">发布于&nbsp;<time datetime="2019-10-25T04:32:50.000Z">2019-10-25</time></div></div>

<article class='content md post'>
<h1 class="article-title"><span>KNN与Naive_Bayes代码实现</span></h1>
<h2 id="任务要求"><a href="#任务要求" class="headerlink" title="任务要求"></a>任务要求</h2><p>采用Python实现分类算法：</p>
<ul>
<li>不得借助现成的工具包调库，例如SKlearn</li>
<li>至少实现k-近邻，朴素贝叶斯，逻辑回归，决策树与支持向量机中的其中一个算法。k-临近，朴素贝叶斯相对较简单，逻辑回归，决策树与支持向量机相对较难。</li>
<li>对breast cancer数据集调用编写的函数进行分类演示。</li>
<li>能力强的可以多实现几种算法</li>
</ul>
<span id="more"></span>
<h2 id="算法实现——kNN"><a href="#算法实现——kNN" class="headerlink" title="算法实现——kNN"></a>算法实现——kNN</h2><p>利用breast_cancer中的数据，实现kNN算法。  </p>
<ol>
<li>导入数据集，并分为训练集和测试集</li>
<li>实现kNN算法<ul>
<li>对每一个测试集中的实例，计算它距离训练集中的点的距离</li>
<li>根据选定的k值，选择距离最近的k个点数量更多的“标签”</li>
</ul>
</li>
<li>算法效果测试，测试算法的精确度，和SKlearn提供的kNN算法进行比较。</li>
</ol>
<h2 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h2><h3 id="导入数据"><a href="#导入数据" class="headerlink" title="导入数据"></a>导入数据</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 导入数据集</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> neighbors</span><br><span class="line"></span><br><span class="line">datasets = datasets.load_breast_cancer()</span><br><span class="line">X = datasets.data;</span><br><span class="line">y = datasets.target;</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="number">0.3</span>, random_state = <span class="number">0</span>)</span><br><span class="line">k = <span class="number">5</span></span><br><span class="line"><span class="comment"># print(datasets.DESCR)</span></span><br><span class="line"><span class="comment"># malignant - 0, benign - 1</span></span><br><span class="line">y_predict = []</span><br></pre></td></tr></table></figure>
<h3 id="kNN算法实现"><a href="#kNN算法实现" class="headerlink" title="kNN算法实现"></a>kNN算法实现</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">knn</span>(<span class="params">X_train, y_train, X_test, y_predict</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    对测试集的数据进行预测，得到的结果与y_test比较。用欧式距离进行计算。</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">for</span> test_data <span class="keyword">in</span> X_test:</span><br><span class="line">        first_k_instance = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(X_train)):</span><br><span class="line">            distance = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">for</span> attributes_no <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(X_train[<span class="number">0</span>])):</span><br><span class="line">                distance += (test_data[attributes_no] - X_train[i][attributes_no]) ** <span class="number">2</span></span><br><span class="line">            Euclid_distance = distance ** <span class="number">0.5</span></span><br><span class="line">            <span class="comment">#print(Euclid_distance)</span></span><br><span class="line">            <span class="keyword">if</span> i &lt; k:</span><br><span class="line">                first_k_instance.append((i, Euclid_distance))</span><br><span class="line">            <span class="keyword">elif</span> Euclid_distance &lt; first_k_instance[k-<span class="number">1</span>][<span class="number">1</span>]:</span><br><span class="line">                first_k_instance[k-<span class="number">1</span>] = (i, Euclid_distance)</span><br><span class="line">            first_k_instance = <span class="built_in">sorted</span>(first_k_instance, key = <span class="keyword">lambda</span> x:x[<span class="number">1</span>]) </span><br><span class="line">            <span class="comment">#print(first_k_instance)</span></span><br><span class="line">        <span class="comment"># 现在得到了距离测试点最近的k个点，用多数表决器来判断测试点是良性还是恶性</span></span><br><span class="line">        benign = <span class="number">0</span></span><br><span class="line">        malignant = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> instance <span class="keyword">in</span> first_k_instance:</span><br><span class="line">            <span class="keyword">if</span> y_train[instance[<span class="number">0</span>]] == <span class="number">0</span>:</span><br><span class="line">                malignant += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                benign += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> malignant &gt;= benign:</span><br><span class="line">            y_predict.append(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            y_predict.append(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h3 id="精确度计算函数"><a href="#精确度计算函数" class="headerlink" title="精确度计算函数"></a>精确度计算函数</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">accuracy</span>(<span class="params">y_predict, y_test</span>):</span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(y_predict)):</span><br><span class="line">        <span class="keyword">if</span> y_predict[i] == y_test[i]:</span><br><span class="line">            correct += <span class="number">1</span></span><br><span class="line">    accuracy_rate = correct / <span class="built_in">len</span>(y_predict)</span><br><span class="line">    <span class="keyword">return</span> correct, accuracy_rate</span><br></pre></td></tr></table></figure>
<h3 id="主函数"><a href="#主函数" class="headerlink" title="主函数"></a>主函数</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    knn(X_train, y_train, X_test, y_predict)</span><br><span class="line">    correct, accuracy_rate = accuracy(y_predict, y_test)</span><br><span class="line">    <span class="built_in">print</span>(y_predict)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;kNN模型测试集预测的准确率为：%.3f&quot;</span> % accuracy_rate);</span><br><span class="line">    KNN = neighbors.KNeighborsClassifier(n_neighbors = <span class="number">5</span>)</span><br><span class="line">    KNN.fit(X_train, y_train)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;sklearn库中kNN模型预测的准确率为：%.3f&quot;</span> % KNN.score(X_test, y_test));</span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<pre><code>[0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1]
kNN模型测试集预测的准确率为：0.947
sklearn库中kNN模型预测的准确率为：0.947
</code></pre><p>通过实验结果可以发现，我们实现的kNN与SKlearn中提供的kNN效果一致。<br>我们可以通过设置k的值和转换寻找相似样本的策略（将欧式距离替换为匹配系数或Jaccard等），进一步优化精确度。</p>
<h2 id="算法实现——Naive-Bayes"><a href="#算法实现——Naive-Bayes" class="headerlink" title="算法实现——Naive_Bayes"></a>算法实现——Naive_Bayes</h2><p>利用breast_cancer中的数据，实现Naive_Bayes算法。  </p>
<ol>
<li>导入数据集，并分为训练集和测试集</li>
<li>实现Naive Bayes算法<ul>
<li>把连续的属性划分区间，计算正例和反例落在每个属性的每个区间的个数</li>
<li>计算概率值，预测测试集的标签</li>
</ul>
</li>
<li>算法效果测试，测试算法的精确度，和SKlearn提供的Naive Bayes算法进行比较。</li>
</ol>
<h2 id="源码-1"><a href="#源码-1" class="headerlink" title="源码"></a>源码</h2><h3 id="导入数据-1"><a href="#导入数据-1" class="headerlink" title="导入数据"></a>导入数据</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># load datasets</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> naive_bayes</span><br><span class="line"></span><br><span class="line">datasets = datasets.load_breast_cancer()</span><br><span class="line">X = datasets.data;</span><br><span class="line">y = datasets.target;</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="number">0.3</span>, random_state = <span class="number">0</span>)</span><br><span class="line"><span class="comment">#print(datasets.DESCR)</span></span><br><span class="line"><span class="comment">#malignant - 0, benign - 1</span></span><br><span class="line">y_predict = []</span><br></pre></td></tr></table></figure>
<p>由于30个属性全部都是连续值，我们使用朴素贝叶斯的时候需要将属性的值的范围分为几个区间，计算实例落在该区间的概率。这里每个属性我都以平均值作为间隔来划分区间。<br><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="2-1.jpg" alt=""></p>
<h3 id="对每个连续的属性划分区间并统计个数"><a href="#对每个连续的属性划分区间并统计个数" class="headerlink" title="对每个连续的属性划分区间并统计个数"></a>对每个连续的属性划分区间并统计个数</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">distribution</span>(<span class="params">X_train, y_train</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    先把区间分好，然后再计算概率。</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment">#===============区间划分====================#</span></span><br><span class="line">    attributes_max_min_mean = []</span><br><span class="line">    <span class="comment"># 记录所有属性的最大值、最小值和平均值</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(X_train[<span class="number">0</span>])):</span><br><span class="line">        <span class="comment">#属性循环</span></span><br><span class="line">        <span class="comment">#section = [max, min, mean]</span></span><br><span class="line">        section = [X_train[<span class="number">0</span>][i], X_train[<span class="number">0</span>][i], <span class="number">0</span>]</span><br><span class="line">        <span class="keyword">for</span> instance <span class="keyword">in</span> X_train:</span><br><span class="line">            <span class="comment">#训练样例循环</span></span><br><span class="line">            <span class="keyword">if</span> instance[i] &gt; section[<span class="number">0</span>]:</span><br><span class="line">                section[<span class="number">0</span>] = instance[i]</span><br><span class="line">            <span class="keyword">if</span> instance[i] &lt; section[<span class="number">1</span>]:</span><br><span class="line">                section[<span class="number">1</span>] = instance[i]</span><br><span class="line">            section[<span class="number">2</span>] += instance[i]</span><br><span class="line">        section[<span class="number">2</span>] /= <span class="built_in">len</span>(X_train)</span><br><span class="line">        attributes_max_min_mean.append(section)</span><br><span class="line">        </span><br><span class="line">    <span class="comment">#=========计算每个属性落在每个区间的样例个数=========#</span></span><br><span class="line">    instance_distribution = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(X_train[<span class="number">0</span>])):</span><br><span class="line">        <span class="comment">#属性循环</span></span><br><span class="line">        smaller_benign = <span class="number">0</span></span><br><span class="line">        larger_benign = <span class="number">0</span></span><br><span class="line">        smaller_malignant = <span class="number">0</span></span><br><span class="line">        larger_malignant = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(X_train)):</span><br><span class="line">            <span class="comment">#训练样例循环</span></span><br><span class="line">            <span class="keyword">if</span> X_train[j][i] &gt; attributes_max_min_mean[i][<span class="number">2</span>]:</span><br><span class="line">                <span class="keyword">if</span> y_train[j] == <span class="number">1</span>:</span><br><span class="line">                    larger_benign += <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    larger_malignant +=<span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> y_train[j] == <span class="number">1</span>:</span><br><span class="line">                smaller_benign += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                smaller_malignant += <span class="number">1</span>   </span><br><span class="line">        instance_distribution.append([smaller_benign, larger_benign, smaller_malignant, larger_malignant])</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> instance_distribution, attributes_max_min_mean</span><br></pre></td></tr></table></figure>
<h3 id="实现朴素贝叶斯"><a href="#实现朴素贝叶斯" class="headerlink" title="实现朴素贝叶斯"></a>实现朴素贝叶斯</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Naive_Bayes</span>(<span class="params">X_test, y_predict, instance_distribution,attributes_max_min_mean</span>):</span><br><span class="line">    <span class="keyword">for</span> test_data <span class="keyword">in</span> X_test:</span><br><span class="line">        <span class="comment">#测试样例循环</span></span><br><span class="line">        <span class="comment">#训练集中良性和恶性肿瘤的数量</span></span><br><span class="line">        malignant = instance_distribution[<span class="number">0</span>][<span class="number">2</span>] + instance_distribution[<span class="number">0</span>][<span class="number">3</span>]</span><br><span class="line">        benign = instance_distribution[<span class="number">0</span>][<span class="number">0</span>] + instance_distribution[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line">        <span class="comment">#概率初始化，下面计算每个属性的概率</span></span><br><span class="line">        p_xc0 = <span class="number">1</span></span><br><span class="line">        p_xc1 = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(X_train[<span class="number">0</span>])):</span><br><span class="line">            <span class="comment"># 属性循环</span></span><br><span class="line">            <span class="keyword">if</span> test_data[i] &gt; attributes_max_min_mean[i][<span class="number">2</span>]:</span><br><span class="line">                p_xc0 *= instance_distribution[i][<span class="number">3</span>] / malignant</span><br><span class="line">                p_xc1 *= instance_distribution[i][<span class="number">1</span>] / benign</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                p_xc0 *= instance_distribution[i][<span class="number">2</span>] / malignant</span><br><span class="line">                p_xc1 *= instance_distribution[i][<span class="number">0</span>] / benign</span><br><span class="line">        p0 = p_xc0 * malignant / (malignant + benign)</span><br><span class="line">        p1 = p_xc1 * benign / (malignant + benign)</span><br><span class="line">        <span class="keyword">if</span> p0 &gt; p1:</span><br><span class="line">            y_predict.append(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            y_predict.append(<span class="number">1</span>)      </span><br></pre></td></tr></table></figure>
<h3 id="计算精确度"><a href="#计算精确度" class="headerlink" title="计算精确度"></a>计算精确度</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">accuracy</span>(<span class="params">y_predict, y_test</span>):</span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(y_predict)):</span><br><span class="line">        <span class="keyword">if</span> y_predict[i] == y_test[i]:</span><br><span class="line">            correct += <span class="number">1</span></span><br><span class="line">    accuracy_rate = correct / <span class="built_in">len</span>(y_predict)</span><br><span class="line">    <span class="keyword">return</span> correct, accuracy_rate</span><br></pre></td></tr></table></figure>
<h3 id="主函数-1"><a href="#主函数-1" class="headerlink" title="主函数"></a>主函数</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    instance_distribution, attributes_max_min_mean = distribution(X_train, y_train)</span><br><span class="line">    Naive_Bayes(X_test, y_predict, instance_distribution, attributes_max_min_mean)</span><br><span class="line">    correct, accuracy_rate = accuracy(y_predict, y_test)</span><br><span class="line">    <span class="built_in">print</span>(y_predict)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Naive Bayes模型测试集预测的准确率为：%.3f&quot;</span> % accuracy_rate);</span><br><span class="line">    bayes = naive_bayes.GaussianNB()</span><br><span class="line">    bayes.fit(X_train, y_train)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;sklearn库中Naive Bayes模型预测的准确率为：%.3f&quot;</span> % bayes.score(X_test, y_test));</span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<pre><code>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1]
Naive Bayes模型测试集预测的准确率为：0.930
sklearn库中Naive Bayes模型预测的准确率为：0.924
</code></pre><p>通过实验结果可以发现，我们实现的朴素贝叶斯比SKlearn提供的朴素贝叶斯效果更好。<br>我们可以通过尝试各属性不同的区间划分，进一步优化精确度。而SKlearn提供的朴素贝叶斯效果不好的原因可能就是将连续值转换为离散值的区间划分没有做好。</p>


<div class="article-footer reveal fs14"><section id="license"><div class="header"><span>许可协议</span></div><div class="body"><p>本文采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">署名-非商业性使用-相同方式共享 4.0 国际</a> 许可协议，转载请注明出处。</p>
</div></section></div>

</article>

<div class="related-wrap reveal" id="read-next"><section class="header cap theme"><span>接下来阅读</span></section><section class="body fs14"><a id="next" href="/201911/Fisher%E7%AE%97%E6%B3%95&SVM&K-Means%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96/">Fisher算法&SVM&K-Means及其优化<span class="note">较早</span></a><div class="line"></div><a id="prev" href="/201910/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%E5%AE%9E%E9%AA%8C%E4%B8%80/">计算机系统基础实验一、Linux环境和GCC工具链<span class="note">较新</span></a></section></div>






  <div class='related-wrap md reveal' id="comments">
    <div class='cmt-title cap theme'>
      快来参与讨论吧
    </div>
    <div class='cmt-body beaudar'>
      

<svg class="loading" style="vertical-align: middle;fill: currentColor;overflow: hidden;" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2709"><path d="M832 512c0-176-144-320-320-320V128c211.2 0 384 172.8 384 384h-64zM192 512c0 176 144 320 320 320v64C300.8 896 128 723.2 128 512h64z" p-id="2710"></path></svg>

<div id="beaudar" repo="CrocodileZS/blog-comments" issue-term="pathname" theme="preferred-color-scheme" input-position="top" comment-order="desc" loading="false" branch="main"></div>

    </div>
  </div>



      
<footer class="page-footer reveal fs12"><hr><div class="text"><p>本博客所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议，转载请注明出处。</p>
<p>本站由 <a href="https://blog.crocodilezs.top/">@CrocodileZS</a> 创建，使用 <a target="_blank" rel="noopener" href="https://github.com/xaoxuu/hexo-theme-stellar/tree/1.7.0" title="v1.7.0">Stellar</a> 作为主题。</p>
</div></footer>

      <div class='float-panel mobile-only blur' style='display:none'>
  <button type='button' class='sidebar-toggle mobile' onclick='sidebar.toggle()'>
    <svg class="icon" style="width: 1em; height: 1em;vertical-align: middle;fill: currentColor;overflow: hidden;" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="15301"><path d="M566.407 808.3c26.9-0.1 49.3-20.8 51.6-47.6-1.9-27.7-23.9-49.7-51.6-51.6h-412.6c-28.2-1.4-52.6 19.5-55.5 47.6 2.3 26.8 24.6 47.5 51.6 47.6h416.5v4z m309.3-249.9c26.9-0.1 49.3-20.8 51.6-47.6-2.2-26.8-24.6-47.5-51.6-47.6h-721.9c-27.7-2.8-52.5 17.4-55.3 45.1-0.1 0.8-0.1 1.7-0.2 2.5 0.9 27.2 23.6 48.5 50.7 47.6H875.707z m-103.1-245.9c26.9-0.1 49.3-20.8 51.6-47.6-0.4-28.3-23.2-51.1-51.5-51.6h-618.9c-29.5-1.1-54.3 21.9-55.5 51.4v0.2c1.4 27.8 25.2 49.2 53 47.8 0.8 0 1.7-0.1 2.5-0.2h618.8z" p-id="15302"></path><path d="M566.407 808.3c26.9-0.1 49.3-20.8 51.6-47.6-1.9-27.7-23.9-49.7-51.6-51.6h-412.6c-28.2-1.4-52.6 19.5-55.5 47.6 1.9 27.7 23.9 49.7 51.6 51.6h416.5z m309.3-249.9c26.9-0.1 49.3-20.8 51.6-47.6-2.2-26.8-24.6-47.5-51.6-47.6h-721.9c-27.7-2.8-52.5 17.4-55.3 45.1-0.1 0.8-0.1 1.7-0.2 2.5 0.9 27.2 23.6 48.5 50.7 47.6H875.707z m-103.1-245.9c26.9-0.1 49.3-20.8 51.6-47.6-0.4-28.3-23.2-51.1-51.5-51.6h-618.9c-29.5-1.1-54.3 21.9-55.5 51.4v0.2c1.4 27.8 25.2 49.2 53 47.8 0.8 0 1.7-0.1 2.5-0.2h618.8z" p-id="15303"></path></svg>
  </button>
</div>

    </div>
  </div>
  <div class='scripts'>
    <script type="text/javascript">
  stellar = {
    // 懒加载 css https://github.com/filamentgroup/loadCSS
    loadCSS: (href, before, media, attributes) => {
      var doc = window.document;
      var ss = doc.createElement("link");
      var ref;
      if (before) {
        ref = before;
      } else {
        var refs = (doc.body || doc.getElementsByTagName("head")[0]).childNodes;
        ref = refs[refs.length - 1];
      }
      var sheets = doc.styleSheets;
      if (attributes) {
        for (var attributeName in attributes) {
          if (attributes.hasOwnProperty(attributeName)) {
            ss.setAttribute(attributeName, attributes[attributeName]);
          }
        }
      }
      ss.rel = "stylesheet";
      ss.href = href;
      ss.media = "only x";
      function ready(cb) {
        if (doc.body) {
          return cb();
        }
        setTimeout(function () {
          ready(cb);
        });
      }
      ready(function () {
        ref.parentNode.insertBefore(ss, before ? ref : ref.nextSibling);
      });
      var onloadcssdefined = function (cb) {
        var resolvedHref = ss.href;
        var i = sheets.length;
        while (i--) {
          if (sheets[i].href === resolvedHref) {
            return cb();
          }
        }
        setTimeout(function () {
          onloadcssdefined(cb);
        });
      };
      function loadCB() {
        if (ss.addEventListener) {
          ss.removeEventListener("load", loadCB);
        }
        ss.media = media || "all";
      }
      if (ss.addEventListener) {
        ss.addEventListener("load", loadCB);
      }
      ss.onloadcssdefined = onloadcssdefined;
      onloadcssdefined(loadCB);
      return ss;
    },

    // 从 butterfly 和 volantis 获得灵感
    loadScript: (src, opt) => new Promise((resolve, reject) => {
      var script = document.createElement('script');
      script.src = src;
      if (opt) {
        for (let key of Object.keys(opt)) {
          script[key] = opt[key]
        }
      } else {
        // 默认异步，如果需要同步，第二个参数传入 {} 即可
        script.async = true
      }
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    }),

    // https://github.com/jerryc127/hexo-theme-butterfly
    jQuery: (fn) => {
      if (typeof jQuery === 'undefined') {
        stellar.loadScript(stellar.plugins.jQuery).then(fn)
      } else {
        fn()
      }
    }
  };
  stellar.github = 'https://github.com/xaoxuu/hexo-theme-stellar/tree/1.7.0';
  stellar.config = {
    date_suffix: {
      just: '刚刚',
      min: '分钟前',
      hour: '小时前',
      day: '天前',
      month: '个月前',
    },
  };

  // required plugins (only load if needs)
  stellar.plugins = {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js',
    sitesjs: '/js/plugins/sites.js',
    friendsjs: '/js/plugins/friends.js',
  };

  // optional plugins
  if ('true' == 'true') {
    stellar.plugins.lazyload = Object.assign({"enable":true,"js":"https://cdn.jsdelivr.net/npm/vanilla-lazyload@17.3.1/dist/lazyload.min.js","transition":"blur"});
  }
  if ('true' == 'true') {
    stellar.plugins.swiper = Object.assign({"enable":true,"css":"https://unpkg.com/swiper@6/swiper-bundle.min.css","js":"https://unpkg.com/swiper@6/swiper-bundle.min.js"});
  }
  if ('' == 'true') {
    stellar.plugins.scrollreveal = Object.assign({"enable":null,"js":"https://cdn.jsdelivr.net/npm/scrollreveal@4.0.9/dist/scrollreveal.min.js","distance":"8px","duration":500,"interval":100,"scale":1});
  }
  if ('true' == 'true') {
    stellar.plugins.preload = Object.assign({"enable":true,"service":"flying_pages","instant_page":"https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@4.1.2/js/instant_page.js","flying_pages":"https://cdn.jsdelivr.net/gh/gijo-varghese/flying-pages@2.1.2/flying-pages.min.js"});
  }
  if ('true' == 'true') {
    stellar.plugins.fancybox = Object.assign({"enable":true,"js":"https://cdn.jsdelivr.net/npm/@fancyapps/ui@4.0/dist/fancybox.umd.js","css":"https://cdn.jsdelivr.net/npm/@fancyapps/ui@4.0/dist/fancybox.css","selector":".swiper-slide img"});
  }
  if ('false' == 'true') {
    stellar.plugins.heti = Object.assign({"enable":false,"css":"https://unpkg.com/heti/umd/heti.min.css","js":"https://unpkg.com/heti/umd/heti-addon.min.js"});
  }
</script>

<!-- required -->

  
<script src="/js/main.js" async></script>



<!-- optional -->

  <script>
  function loadBeaudar() {
    const els = document.querySelectorAll("#comments #beaudar");
    if (els.length === 0) return;
    els.forEach((el, i) => {
      try {
        el.innerHTML = '';
      } catch (error) {
        console.log(error);
      }
      var script = document.createElement('script');
      script.src = 'https://beaudar.lipk.org/client.js';
      script.async = true;
      for (let key of Object.keys(el.attributes)) {
        let attr = el.attributes[key];
        if (['class', 'id'].includes(attr.name) === false) {
          script.setAttribute(attr.name, attr.value);
        }
      }
      el.appendChild(script);
    });
  }
  window.addEventListener('DOMContentLoaded', (event) => {
      loadBeaudar();
  });
</script>




<!-- inject -->


  </div>
</body>
</html>
